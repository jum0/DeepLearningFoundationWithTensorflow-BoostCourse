{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X and Y data\n",
    "x_train = [1, 2, 3]\n",
    "y_train = [1, 2, 3]\n",
    "\n",
    "W = tf.Variable(2.9)\n",
    "b = tf.Variable(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our hypothesis XW+b\n",
    "hypothesis = x_train * W + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning reate\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0|    2.7027|    0.4140| 20.896669\n",
      "  100|    1.0971|   -0.2206|  0.007018\n",
      "  200|    1.0763|   -0.1734|  0.004337\n",
      "  300|    1.0600|   -0.1363|  0.002680\n",
      "  400|    1.0471|   -0.1072|  0.001656\n",
      "  500|    1.0371|   -0.0843|  0.001023\n",
      "  600|    1.0291|   -0.0662|  0.000632\n",
      "  700|    1.0229|   -0.0521|  0.000391\n",
      "  800|    1.0180|   -0.0409|  0.000241\n",
      "  900|    1.0142|   -0.0322|  0.000149\n",
      " 1000|    1.0111|   -0.0253|  0.000092\n",
      " 1100|    1.0087|   -0.0199|  0.000057\n",
      " 1200|    1.0069|   -0.0156|  0.000035\n",
      " 1300|    1.0054|   -0.0123|  0.000022\n",
      " 1400|    1.0042|   -0.0097|  0.000013\n",
      " 1500|    1.0033|   -0.0076|  0.000008\n",
      " 1600|    1.0026|   -0.0060|  0.000005\n",
      " 1700|    1.0021|   -0.0047|  0.000003\n",
      " 1800|    1.0016|   -0.0037|  0.000002\n",
      " 1900|    1.0013|   -0.0029|  0.000001\n",
      " 2000|    1.0010|   -0.0023|  0.000001\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# W, b update\n",
    "for step in range(2001):\n",
    "    # Gradient descent\n",
    "    # GradientTape()은 보통 with 구문과 같이 쓰이는데, with 구문 안의 변수들의 변화(기록)를 tape에 기록\n",
    "    with tf.GradientTape() as tape:\n",
    "        hypothesis = W * x_train + b # 여기서는 W와 b에\n",
    "        cost = tf.reduce_mean(tf.square(hypothesis - y_train))\n",
    "    # 이후에 tape의 gradient 메서드를 호출해서 경사도(미분값)을 구한다\n",
    "    # gradient(cost, [W, b])는 함수 cost의 변수 W, b에 대한 개별 미분값(기울기)을 구해서 tuple로 반환\n",
    "    W_grad, b_grad = tape.gradient(cost, [W, b])\n",
    "    W.assign_sub(learning_rate * W_grad) # A.assign_sub(B) -> A = A - B\n",
    "    b.assign_sub(learning_rate * b_grad)\n",
    "    if step % 100 == 0:\n",
    "      print(\"{:5}|{:10.4f}|{:10.4f}|{:10.6f}\".format(step, W.numpy(), b.numpy(), cost))\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
