{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": true,
    "id": "qa55_des11wj",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 03 - Multi-variable Linear Regression\n",
    "\n",
    "<img width=\"200\" src=\"https://i.imgur.com/hbPVe1T.png\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1622,
     "status": "ok",
     "timestamp": 1549861753492,
     "user": {
      "displayName": "Sean-June Lee",
      "photoUrl": "https://lh3.googleusercontent.com/-j96Pvw9LbEw/AAAAAAAAAAI/AAAAAAACQxw/aY8i4PoItwc/s64/photo.jpg",
      "userId": "12576390002043678893"
     },
     "user_tz": -540
    },
    "id": "BbOQ25cb11wl",
    "outputId": "182e949f-9183-4095-84bb-3edcf3f768fa",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3.1'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eXdPAm1y11xP",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Multi-variable linear regression\n",
    "Predicting exam score - regression using three inputs (x1, x2, x3)\n",
    "\n",
    "x1 (quiz 1) | x2 (quiz 2) | x3 (mid 1) | Y (final)\n",
    "---- | ---- | ----| ----\n",
    "73 | 80 | 75 | 152\n",
    "93 | 88 | 93 | 185\n",
    "89 | 91 | 90 | 180\n",
    "96 | 98 | 100 | 196\n",
    "73 | 66 | 70 | 142\n",
    "\n",
    "\n",
    "Test Scores for General Psychology ( https://goo.gl/g2T8Kp )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZCc0H5qT11xU",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Matrix multiplication\n",
    "\n",
    "## dot product(=scalar product, 내적)\n",
    "<img src=\"https://www.mathsisfun.com/algebra/images/matrix-multiply-a.svg\" >\n",
    "\n",
    "\n",
    "https://www.mathsisfun.com/algebra/matrix-multiplying.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HOpVHPfX11xV",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Multi-feature regression\n",
    "\n",
    "### Hypothesis\n",
    "\n",
    "$$ H(x) = w x + b $$\n",
    "\n",
    "$$ H(x_1, x_2, x_3) = w_1 x_1 + w_2 x_2 + w_3 x_3 + b $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jiJiS73i11xW",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Hypothesis using matrix\n",
    "\n",
    "$$ H(x_1, x_2, x_3) = \\underline{w_1 x_1 + w_2 x_2 + w_3 x_3} + b $$\n",
    "\n",
    "$$ w_1 x_1 + w_2 x_2 + w_3 x_3 $$ \n",
    "\n",
    "$$ \\begin{pmatrix} w_{ 1 } & w_{ 2 } & w_{ 3 } \\end{pmatrix}\\cdot \\begin{pmatrix} x_{ 1 } \\\\ x_{ 2 } \\\\ x_{ 3 } \\end{pmatrix} $$\n",
    "\n",
    "$$ WX $$ (W, X 는 matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Qyo_v2q211xX",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Hypothesis without b\n",
    "\n",
    "$$ H(x_1, x_2, x_3) = w_1 x_1 + w_2 x_2 + w_3 x_3 + b$$\n",
    "\n",
    "$$ = b + w_1 x_1 + w_2 x_2 + w_3 x_3 $$\n",
    "\n",
    "$$ = \\begin{pmatrix} b & x_{ 1 } & x_{ 2 } & x_{ 3 } \\end{pmatrix}\\cdot \\begin{pmatrix} 1 \\\\ w_{ 1 } \\\\ w_{ 2 } \\\\ w_{ 3 } \\end{pmatrix} $$\n",
    "\n",
    "$$ = XW $$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "70JryWbi11xZ",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Hypothesis using matrix \n",
    "\n",
    "### Many x instances\n",
    "\n",
    "$$ \\begin{pmatrix} x_{ 11 } & x_{ 12 } & x_{ 13 } \\\\ x_{ 21 } & x_{ 22 } & x_{ 23 } \\\\ x_{ 31 } & x_{ 32 } & x_{ 33 }\\\\ x_{ 41 } & x_{ 42 } & x_{ 43 }\\\\ x_{ 51 } & x_{ 52 } & x_{ 53 }\\end{pmatrix} \\cdot \\begin{pmatrix} w_{ 1 } \\\\ w_{ 2 } \\\\ w_{ 3 } \\end{pmatrix}=\\begin{pmatrix} x_{ 11 }w_{ 1 }+x_{ 12 }w_{ 2 }+x_{ 13 }w_{ 3 } \\\\ x_{ 21 }w_{ 1 }+x_{ 22 }w_{ 2 }+x_{ 23 }w_{ 3 }\\\\ x_{ 31 }w_{ 1 }+x_{ 32 }w_{ 2 }+x_{ 33 }w_{ 3 } \\\\ x_{ 41 }w_{ 1 }+x_{ 42 }w_{ 2 }+x_{ 43 }w_{ 3 } \\\\ x_{ 51 }w_{ 1 }+x_{ 52 }w_{ 2 }+x_{ 53 }w_{ 3 } \\end{pmatrix} $$\n",
    "\n",
    "$$ [5, 3] \\cdot [3, 1] = [5, 1] $$\n",
    "\n",
    "$$ H(X) = XW $$\n",
    "\n",
    "5는 데이터(instance)의 수, 3은 변수(feature)의 수, 1은 결과"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_PmX23KO11xc",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Hypothesis using matrix (n output)\n",
    "\n",
    "$$ [n, 3] \\cdot [?, ?] = [n, 2] $$\n",
    "\n",
    "$$ H(X) = XW $$\n",
    "\n",
    "* n은 데이터(instance)의 개수, 2는 결과 값의 개수로 주어진다.\n",
    "* 이때, W [?, ?] ⇒ [3, 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TdLqWOL811xd",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# WX vs XW\n",
    "\n",
    "### Theory (Lecture) :\n",
    " $$ H(x) = Wx + b  $$\n",
    "\n",
    "### TensorFlow (Implementation) :\n",
    "\n",
    "$$ H(X) = XW $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4hzOpk9w11xf",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Simple Example (2 variables)\n",
    "\n",
    "x1 | x2 | y\n",
    "---- | ---- | ----\n",
    "1  |  0  |  1\n",
    "0  |  2  |  2\n",
    "3  |  0  |  3\n",
    "0  |  4  |  4\n",
    "5  |  0  |  5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b645aPucdmMz"
   },
   "outputs": [],
   "source": [
    "# tf.set_random_seed(0)  # for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 386
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2134,
     "status": "ok",
     "timestamp": 1549859056786,
     "user": {
      "displayName": "Sean-June Lee",
      "photoUrl": "https://lh3.googleusercontent.com/-j96Pvw9LbEw/AAAAAAAAAAI/AAAAAAACQxw/aY8i4PoItwc/s64/photo.jpg",
      "userId": "12576390002043678893"
     },
     "user_tz": -540
    },
    "id": "XdIC0_tqpmc1",
    "outputId": "441c62e7-dac2-48ee-affe-fcd6e346cce1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0 | 273.989380 |     2.7632 |     3.7846 |   9.515614\n",
      "   50 |  86.624954 |     0.7280 |     1.9885 |   8.296487\n",
      "  100 |  33.762535 |    -0.1597 |     0.8777 |   7.594676\n",
      "  150 |  17.115639 |    -0.5281 |     0.1886 |   7.162701\n",
      "  200 |  11.236509 |    -0.6652 |    -0.2380 |   6.875246\n",
      "  250 |   8.908846 |    -0.7017 |    -0.4994 |   6.667512\n",
      "  300 |   7.862996 |    -0.6962 |    -0.6564 |   6.505186\n",
      "  350 |   7.312510 |    -0.6745 |    -0.7468 |   6.369628\n",
      "  400 |   6.963546 |    -0.6473 |    -0.7948 |   6.250434\n",
      "  450 |   6.700599 |    -0.6192 |    -0.8156 |   6.141641\n",
      "  500 |   6.476808 |    -0.5917 |    -0.8192 |   6.039755\n",
      "  550 |   6.272764 |    -0.5652 |    -0.8117 |   5.942668\n",
      "  600 |   6.080301 |    -0.5397 |    -0.7973 |   5.849095\n",
      "  650 |   5.895909 |    -0.5152 |    -0.7785 |   5.758232\n",
      "  700 |   5.718015 |    -0.4914 |    -0.7570 |   5.669565\n",
      "  750 |   5.545869 |    -0.4682 |    -0.7339 |   5.582766\n",
      "  800 |   5.379067 |    -0.4456 |    -0.7099 |   5.497619\n",
      "  850 |   5.217346 |    -0.4235 |    -0.6855 |   5.413977\n",
      "  900 |   5.060517 |    -0.4018 |    -0.6609 |   5.331742\n",
      "  950 |   4.908413 |    -0.3804 |    -0.6364 |   5.250842\n",
      " 1000 |   4.760887 |    -0.3595 |    -0.6120 |   5.171225\n"
     ]
    }
   ],
   "source": [
    "x1_data = [1, 0, 3, 0, 5]\n",
    "x2_data = [0, 2, 0, 4, 0]\n",
    "y_data  = [1, 2, 3, 4, 5]\n",
    "\n",
    "W1 = tf.Variable(tf.random.uniform([1], -10.0, 10.0))\n",
    "W2 = tf.Variable(tf.random.uniform([1], -10.0, 10.0))\n",
    "b  = tf.Variable(tf.random.uniform([1], -10.0, 10.0))\n",
    "\n",
    "learning_rate = tf.Variable(0.001)\n",
    "\n",
    "for i in range(1000+1):\n",
    "    with tf.GradientTape() as tape:\n",
    "        hypothesis = W1 * x1_data + W2 * x2_data + b\n",
    "        cost = tf.reduce_mean(tf.square(hypothesis - y_data))\n",
    "    W1_grad, W2_grad, b_grad = tape.gradient(cost, [W1, W2, b])\n",
    "    W1.assign_sub(learning_rate * W1_grad)\n",
    "    W2.assign_sub(learning_rate * W2_grad)\n",
    "    b.assign_sub(learning_rate * b_grad)\n",
    "\n",
    "    if i % 50 == 0:\n",
    "        print(\"{:5} | {:10.6f} | {:10.4f} | {:10.4f} | {:10.6f}\".format(\n",
    "          i, cost.numpy(), W1.numpy()[0], W2.numpy()[0], b.numpy()[0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uNHVQS-311xk",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Simple Example (2 variables with Matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 386
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3709,
     "status": "ok",
     "timestamp": 1549859058376,
     "user": {
      "displayName": "Sean-June Lee",
      "photoUrl": "https://lh3.googleusercontent.com/-j96Pvw9LbEw/AAAAAAAAAAI/AAAAAAACQxw/aY8i4PoItwc/s64/photo.jpg",
      "userId": "12576390002043678893"
     },
     "user_tz": -540
    },
    "id": "1SWH2f6vnjCO",
    "outputId": "e37b1216-8540-4aa1-ea9e-3a52761230c0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0 |  10.959678 |     0.8727 |    -0.4902 |  -0.397449\n",
      "   50 |   4.384669 |     0.9743 |     0.0316 |  -0.209530\n",
      "  100 |   1.794316 |     1.0060 |     0.3664 |  -0.098260\n",
      "  150 |   0.743826 |     1.0106 |     0.5820 |  -0.031300\n",
      "  200 |   0.310794 |     1.0062 |     0.7211 |   0.009460\n",
      "  250 |   0.130689 |     0.9999 |     0.8110 |   0.034420\n",
      "  300 |   0.055412 |     0.9943 |     0.8692 |   0.049698\n",
      "  350 |   0.023860 |     0.9900 |     0.9070 |   0.058964\n",
      "  400 |   0.010608 |     0.9870 |     0.9316 |   0.064462\n",
      "  450 |   0.005027 |     0.9849 |     0.9477 |   0.067579\n",
      "  500 |   0.002667 |     0.9836 |     0.9582 |   0.069186\n",
      "  550 |   0.001659 |     0.9829 |     0.9651 |   0.069832\n",
      "  600 |   0.001220 |     0.9824 |     0.9697 |   0.069868\n",
      "  650 |   0.001019 |     0.9823 |     0.9728 |   0.069516\n",
      "  700 |   0.000920 |     0.9822 |     0.9749 |   0.068920\n",
      "  750 |   0.000863 |     0.9823 |     0.9764 |   0.068172\n",
      "  800 |   0.000825 |     0.9824 |     0.9775 |   0.067331\n",
      "  850 |   0.000795 |     0.9826 |     0.9783 |   0.066435\n",
      "  900 |   0.000769 |     0.9828 |     0.9789 |   0.065509\n",
      "  950 |   0.000745 |     0.9831 |     0.9795 |   0.064569\n",
      " 1000 |   0.000723 |     0.9833 |     0.9799 |   0.063625\n"
     ]
    }
   ],
   "source": [
    "x_data = [\n",
    "    [1., 0., 3., 0., 5.],\n",
    "    [0., 2., 0., 4., 0.]\n",
    "]\n",
    "y_data  = [1, 2, 3, 4, 5]\n",
    "\n",
    "W = tf.Variable(tf.random.uniform([1, 2], -1.0, 1.0))\n",
    "b = tf.Variable(tf.random.uniform([1], -1.0, 1.0))\n",
    "\n",
    "learning_rate = tf.Variable(0.001)\n",
    "\n",
    "for i in range(1000+1):\n",
    "    with tf.GradientTape() as tape:\n",
    "        hypothesis = tf.matmul(W, x_data) + b # (1, 2) * (2, 5) = (1, 5)\n",
    "        cost = tf.reduce_mean(tf.square(hypothesis - y_data))\n",
    "\n",
    "        W_grad, b_grad = tape.gradient(cost, [W, b])\n",
    "        W.assign_sub(learning_rate * W_grad)\n",
    "        b.assign_sub(learning_rate * b_grad)\n",
    "    \n",
    "    if i % 50 == 0:\n",
    "        print(\"{:5} | {:10.6f} | {:10.4f} | {:10.4f} | {:10.6f}\".format(\n",
    "            i, cost.numpy(), W.numpy()[0][0], W.numpy()[0][1], b.numpy()[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GUs7qbTR11xs",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Hypothesis without b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 386
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3701,
     "status": "ok",
     "timestamp": 1549859058377,
     "user": {
      "displayName": "Sean-June Lee",
      "photoUrl": "https://lh3.googleusercontent.com/-j96Pvw9LbEw/AAAAAAAAAAI/AAAAAAACQxw/aY8i4PoItwc/s64/photo.jpg",
      "userId": "12576390002043678893"
     },
     "user_tz": -540
    },
    "id": "114nIzJq5EuC",
    "outputId": "7b4a0292-0128-4a94-dfac-725f1311ecae"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow._api.v2.train' has no attribute 'GradientDescentOptimizer'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-76915b5d90d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.001\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientDescentOptimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow._api.v2.train' has no attribute 'GradientDescentOptimizer'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# 앞의 코드에서 bias(b)를 행렬에 추가\n",
    "x_data = [\n",
    "    [1., 1., 1., 1., 1.], # bias(b)\n",
    "    [1., 0., 3., 0., 5.], \n",
    "    [0., 2., 0., 4., 0.]\n",
    "]\n",
    "y_data  = [1, 2, 3, 4, 5]\n",
    "\n",
    "W = tf.Variable(tf.random.uniform([1, 3], -1.0, 1.0)) # [1, 3]으로 변경하고, b 삭제\n",
    "\n",
    "learning_rate = 0.001\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "\n",
    "for i in range(1000+1):\n",
    "    with tf.GradientTape() as tape:\n",
    "        hypothesis = tf.matmul(W, x_data) # b가 없다\n",
    "        cost = tf.reduce_mean(tf.square(hypothesis - y_data))\n",
    "\n",
    "    grads = tape.gradient(cost, [W])\n",
    "    optimizer.apply_gradients(grads_and_vars=zip(grads,[W]))\n",
    "    if i % 50 == 0:\n",
    "        print(\"{:5} | {:10.6f} | {:10.4f} | {:10.4f} | {:10.4f}\".format(\n",
    "            i, cost.numpy(), W.numpy()[0][0], W.numpy()[0][1], W.numpy()[0][2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ivo2V3xK11xx"
   },
   "source": [
    "# Custom Gradient\n",
    "* tf.train.GradientDescentOptimizer(): optimizer\n",
    "* optimizer.apply_gradients(): update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 404
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6779,
     "status": "ok",
     "timestamp": 1549859061465,
     "user": {
      "displayName": "Sean-June Lee",
      "photoUrl": "https://lh3.googleusercontent.com/-j96Pvw9LbEw/AAAAAAAAAAI/AAAAAAACQxw/aY8i4PoItwc/s64/photo.jpg",
      "userId": "12576390002043678893"
     },
     "user_tz": -540
    },
    "id": "QkPqZbkDiqe7",
    "outputId": "89754887-b544-4908-9e2d-2d9ab0dabc40"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow._api.v2.train' has no attribute 'GradientDescentOptimizer'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-6d9a7b1a308c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Create an optimizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientDescentOptimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mn_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow._api.v2.train' has no attribute 'GradientDescentOptimizer'"
     ]
    }
   ],
   "source": [
    "# Multi-variable linear regression (1)\n",
    "\n",
    "X = tf.constant([[1., 2.], \n",
    "                 [3., 4.]])\n",
    "y = tf.constant([[1.5], [3.5]])\n",
    "\n",
    "W = tf.Variable(tf.random.normal([2, 1]))\n",
    "b = tf.Variable(tf.random.normal([1]))\n",
    "\n",
    "# Create an optimizer\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "\n",
    "n_epoch = 1000+1\n",
    "print(\"epoch | cost\")\n",
    "for i in range(n_epoch):\n",
    "    # Use tf.GradientTape() to record the gradient of the cost function\n",
    "    with tf.GradientTape() as tape:\n",
    "        y_pred = tf.matmul(X, W) + b\n",
    "        cost = tf.reduce_mean(tf.square(y_pred - y))\n",
    "\n",
    "    # calculates the gradients of the loss\n",
    "    grads = tape.gradient(cost, [W, b])\n",
    "    \n",
    "    # updates parameters (W and b)\n",
    "    optimizer.apply_gradients(grads_and_vars=zip(grads, [W, b]))\n",
    "    if i % 50 == 0:\n",
    "        print(\"{:5} | {:10.6f}\".format(i, cost.numpy()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kGyEI57HLRWl"
   },
   "source": [
    "# Predicting exam score\n",
    "regression using three inputs (x1, x2, x3)\n",
    "\n",
    "x1 (quiz 1) | x2 (quiz 2) | x3 (mid 1) | Y (final)\n",
    "---- | ---- | ----| ----\n",
    "73 | 80 | 75 | 152\n",
    "93 | 88 | 93 | 185\n",
    "89 | 91 | 90 | 180\n",
    "96 | 98 | 100 | 196\n",
    "73 | 66 | 70 | 142"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ny-s4htZ4Lzo"
   },
   "outputs": [],
   "source": [
    "# tf.set_random_seed(0)  # for reproducibility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F1bSir9448BC"
   },
   "source": [
    "\n",
    "```python\n",
    "x1 = [ 73.,  93.,  89.,  96.,  73.]\n",
    "x2 = [ 80.,  88.,  91.,  98.,  66.]\n",
    "x3 = [ 75.,  93.,  90., 100.,  70.]\n",
    "Y  = [152., 185., 180., 196., 142.]\n",
    "\n",
    "# weights\n",
    "w1 = tf.Variable(10.)\n",
    "w2 = tf.Variable(10.)\n",
    "w3 = tf.Variable(10.)\n",
    "b  = tf.Variable(10.)\n",
    "\n",
    "hypothesis = w1 * x1 +  w2 * x2 + w3 * x3 + b        \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 386
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2003,
     "status": "ok",
     "timestamp": 1549861013021,
     "user": {
      "displayName": "Sean-June Lee",
      "photoUrl": "https://lh3.googleusercontent.com/-j96Pvw9LbEw/AAAAAAAAAAI/AAAAAAACQxw/aY8i4PoItwc/s64/photo.jpg",
      "userId": "12576390002043678893"
     },
     "user_tz": -540
    },
    "id": "ICTAblBh-3FO",
    "outputId": "f364e89a-1df9-4635-a1ae-7a4b10a56659"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0 | 5793889.5000\n",
      "   50 |   64291.1562\n",
      "  100 |     715.2903\n",
      "  150 |       9.8461\n",
      "  200 |       2.0152\n",
      "  250 |       1.9252\n",
      "  300 |       1.9210\n",
      "  350 |       1.9177\n",
      "  400 |       1.9145\n",
      "  450 |       1.9114\n",
      "  500 |       1.9081\n",
      "  550 |       1.9050\n",
      "  600 |       1.9018\n",
      "  650 |       1.8986\n",
      "  700 |       1.8955\n",
      "  750 |       1.8923\n",
      "  800 |       1.8892\n",
      "  850 |       1.8861\n",
      "  900 |       1.8829\n",
      "  950 |       1.8798\n",
      " 1000 |       1.8767\n"
     ]
    }
   ],
   "source": [
    "# data and label\n",
    "x1 = [ 73.,  93.,  89.,  96.,  73.]\n",
    "x2 = [ 80.,  88.,  91.,  98.,  66.]\n",
    "x3 = [ 75.,  93.,  90., 100.,  70.]\n",
    "Y  = [152., 185., 180., 196., 142.]\n",
    "\n",
    "# weights\n",
    "w1 = tf.Variable(10.)\n",
    "w2 = tf.Variable(10.)\n",
    "w3 = tf.Variable(10.)\n",
    "b  = tf.Variable(10.)\n",
    "\n",
    "learning_rate = 0.000001\n",
    "\n",
    "for i in range(1000+1):\n",
    "    # tf.GradientTape() to record the gradient of the cost function\n",
    "    with tf.GradientTape() as tape:\n",
    "        hypothesis = w1 * x1 +  w2 * x2 + w3 * x3 + b\n",
    "        cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "    # calculates the gradients of the cost\n",
    "    w1_grad, w2_grad, w3_grad, b_grad = tape.gradient(cost, [w1, w2, w3, b])\n",
    "    \n",
    "    # update w1,w2,w3 and b\n",
    "    w1.assign_sub(learning_rate * w1_grad)\n",
    "    w2.assign_sub(learning_rate * w2_grad)\n",
    "    w3.assign_sub(learning_rate * w3_grad)\n",
    "    b.assign_sub(learning_rate * b_grad)\n",
    "\n",
    "    if i % 50 == 0:\n",
    "      print(\"{:5} | {:12.4f}\".format(i, cost.numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ptg1sl3w8uFt"
   },
   "source": [
    "## Multi-variable linear regression (1)\n",
    "*  random  초기화: tf.random_normal()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 386
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1992,
     "status": "ok",
     "timestamp": 1549861572665,
     "user": {
      "displayName": "Sean-June Lee",
      "photoUrl": "https://lh3.googleusercontent.com/-j96Pvw9LbEw/AAAAAAAAAAI/AAAAAAACQxw/aY8i4PoItwc/s64/photo.jpg",
      "userId": "12576390002043678893"
     },
     "user_tz": -540
    },
    "id": "LhczGchq_zzQ",
    "outputId": "37949eab-e23e-4ef3-997a-e0e02f63daa3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0 |   34129.2539\n",
      "   50 |     418.9921\n",
      "  100 |      44.8339\n",
      "  150 |      40.5749\n",
      "  200 |      40.4204\n",
      "  250 |      40.3118\n",
      "  300 |      40.2040\n",
      "  350 |      40.0964\n",
      "  400 |      39.9892\n",
      "  450 |      39.8823\n",
      "  500 |      39.7756\n",
      "  550 |      39.6693\n",
      "  600 |      39.5632\n",
      "  650 |      39.4576\n",
      "  700 |      39.3520\n",
      "  750 |      39.2467\n",
      "  800 |      39.1418\n",
      "  850 |      39.0373\n",
      "  900 |      38.9329\n",
      "  950 |      38.8288\n",
      " 1000 |      38.7251\n"
     ]
    }
   ],
   "source": [
    "# data and label\n",
    "x1 = [ 73.,  93.,  89.,  96.,  73.]\n",
    "x2 = [ 80.,  88.,  91.,  98.,  66.]\n",
    "x3 = [ 75.,  93.,  90., 100.,  70.]\n",
    "Y  = [152., 185., 180., 196., 142.]\n",
    "\n",
    "# random weights\n",
    "w1 = tf.Variable(tf.random.normal([1]))\n",
    "w2 = tf.Variable(tf.random.normal([1]))\n",
    "w3 = tf.Variable(tf.random.normal([1]))\n",
    "b  = tf.Variable(tf.random.normal([1]))\n",
    "\n",
    "learning_rate = 0.000001\n",
    "\n",
    "for i in range(1000+1):\n",
    "    # tf.GradientTape() to record the gradient of the cost function\n",
    "    with tf.GradientTape() as tape:\n",
    "        hypothesis = w1 * x1 +  w2 * x2 + w3 * x3 + b\n",
    "        cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "    # calculates the gradients of the cost\n",
    "    w1_grad, w2_grad, w3_grad, b_grad = tape.gradient(cost, [w1, w2, w3, b])\n",
    "    \n",
    "    # update w1,w2,w3 and b\n",
    "    w1.assign_sub(learning_rate * w1_grad)\n",
    "    w2.assign_sub(learning_rate * w2_grad)\n",
    "    w3.assign_sub(learning_rate * w3_grad)\n",
    "    b.assign_sub(learning_rate * b_grad)\n",
    "\n",
    "    if i % 50 == 0:\n",
    "      print(\"{:5} | {:12.4f}\".format(i, cost.numpy()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7w0kEX9C82D8"
   },
   "source": [
    "## Multi-variable linear regression (2)\n",
    "\n",
    "* Matrix 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 404
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2082,
     "status": "ok",
     "timestamp": 1549861764291,
     "user": {
      "displayName": "Sean-June Lee",
      "photoUrl": "https://lh3.googleusercontent.com/-j96Pvw9LbEw/AAAAAAAAAAI/AAAAAAACQxw/aY8i4PoItwc/s64/photo.jpg",
      "userId": "12576390002043678893"
     },
     "user_tz": -540
    },
    "id": "mmNogkEuQe5K",
    "outputId": "025477a5-868f-413d-fb4c-678f9510a6be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch | cost\n",
      "    0 | 19757.1992\n",
      "  100 |    53.3506\n",
      "  200 |    50.6608\n",
      "  300 |    50.3981\n",
      "  400 |    50.1373\n",
      "  500 |    49.8777\n",
      "  600 |    49.6196\n",
      "  700 |    49.3629\n",
      "  800 |    49.1076\n",
      "  900 |    48.8535\n",
      " 1000 |    48.6009\n",
      " 1100 |    48.3496\n",
      " 1200 |    48.0998\n",
      " 1300 |    47.8512\n",
      " 1400 |    47.6040\n",
      " 1500 |    47.3582\n",
      " 1600 |    47.1136\n",
      " 1700 |    46.8703\n",
      " 1800 |    46.6285\n",
      " 1900 |    46.3878\n",
      " 2000 |    46.1486\n"
     ]
    }
   ],
   "source": [
    "data = np.array([\n",
    "    # X1,   X2,    X3,   y\n",
    "    [ 73.,  80.,  75., 152. ],\n",
    "    [ 93.,  88.,  93., 185. ],\n",
    "    [ 89.,  91.,  90., 180. ],\n",
    "    [ 96.,  98., 100., 196. ],\n",
    "    [ 73.,  66.,  70., 142. ]\n",
    "], dtype=np.float32)\n",
    "\n",
    "# slice data\n",
    "X = data[:, :-1]\n",
    "y = data[:, [-1]]\n",
    "\n",
    "W = tf.Variable(tf.random.normal([3, 1]))\n",
    "b = tf.Variable(tf.random.normal([1]))\n",
    "\n",
    "learning_rate = 0.000001\n",
    "\n",
    "# hypothesis, prediction function\n",
    "def predict(X):\n",
    "    return tf.matmul(X, W) + b\n",
    "\n",
    "print(\"epoch | cost\")\n",
    "\n",
    "n_epochs = 2000\n",
    "for i in range(n_epochs+1):\n",
    "    # tf.GradientTape() to record the gradient of the cost function\n",
    "    with tf.GradientTape() as tape:\n",
    "        cost = tf.reduce_mean((tf.square(predict(X) - y)))\n",
    "\n",
    "    # calculates the gradients of the loss\n",
    "    W_grad, b_grad = tape.gradient(cost, [W, b])\n",
    "\n",
    "    # updates parameters (W and b)\n",
    "    W.assign_sub(learning_rate * W_grad)\n",
    "    b.assign_sub(learning_rate * b_grad)\n",
    "    \n",
    "    if i % 100 == 0:\n",
    "        print(\"{:5} | {:10.4f}\".format(i, cost.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mt9zvM2OaljB"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.3089204 ],\n",
       "       [0.37783653],\n",
       "       [0.32083523]], dtype=float32)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eCTzJDjH2k4z"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.1783521], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Cs-KBzAHCf2u"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=383121, shape=(5, 1), dtype=float32, numpy=\n",
       "array([[160.38487],\n",
       "       [178.98064],\n",
       "       [184.08965],\n",
       "       [194.17314],\n",
       "       [138.03304]], dtype=float32)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.matmul(X, W) + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9FgoGhG8GxEW"
   },
   "source": [
    "## predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0ZcVkvquG0g5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[152.0, 185.0, 180.0, 196.0, 142.0]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y # labels, 실제값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f_YW4xsrGZAE"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[160.38487],\n",
       "       [178.98064],\n",
       "       [184.08965],\n",
       "       [194.17314],\n",
       "       [138.03304]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(X).numpy() # prediction, 예측값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QrXNF_NSHZGo"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[189.66275],\n",
       "       [186.46652]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 새로운 데이터에 대한 예측\n",
    "\n",
    "predict([[ 89.,  95.,  92.],[ 84.,  92.,  85.]]).numpy() "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "lab-04-1-Multi-variable-Linear-Regression-eager.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
